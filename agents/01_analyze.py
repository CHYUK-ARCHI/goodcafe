#!/usr/bin/env python3
"""
Agent 01: Repository Analysis Agent
====================================
Re-Archive (goodcafe) ë ˆí¬ì§€í† ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬:
- íŒŒì¼ êµ¬ì¡° ë° ì˜ì¡´ì„± ë§¤í•‘
- ëˆ„ë½ëœ íŒŒì¼/ê¸°ëŠ¥ ê°ì§€
- ì½”ë“œ í’ˆì§ˆ ì´ìŠˆ ë¦¬í¬íŠ¸
- ë¶„ì„ ê²°ê³¼ë¥¼ reports/analysis.mdë¡œ ì €ì¥

Usage:
    python3 agents/01_analyze.py
    python3 agents/01_analyze.py --verbose
    python3 agents/01_analyze.py --output reports/custom.md
"""

import os
import re
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from collections import defaultdict


# â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ROOT = Path(__file__).parent.parent
REPORTS_DIR = ROOT / "reports"
OUTPUT_FILE = REPORTS_DIR / "analysis.md"

IGNORE_DIRS = {".git", "node_modules", "__pycache__", ".jekyll-cache", "_site"}
IGNORE_FILES = {".DS_Store", "Thumbs.db", ".gitignore"}

# ë¶„ì„ ëŒ€ìƒ í™•ì¥ì â†’ ì¹´í…Œê³ ë¦¬
EXT_CATEGORIES = {
    ".html": "HTML",
    ".css": "CSS",
    ".js": "JavaScript",
    ".md": "Markdown",
    ".json": "JSON",
    ".py": "Python",
    ".sh": "Shell",
    ".jpg": "Image",
    ".jpeg": "Image",
    ".png": "Image",
    ".gif": "Image",
    ".svg": "Image",
    ".webp": "Image",
    ".webm": "Video",
    ".mp4": "Video",
    ".woff": "Font",
    ".woff2": "Font",
    ".ttf": "Font",
}


# â”€â”€â”€ ìœ í‹¸ë¦¬í‹° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def log(msg: str, level: str = "INFO", verbose: bool = True):
    if verbose or level in ("WARN", "ERROR"):
        icons = {"INFO": "â„¹", "WARN": "âš ", "ERROR": "âœ—", "OK": "âœ“"}
        print(f"  {icons.get(level, 'Â·')} {msg}")


def count_lines(path: Path) -> int:
    try:
        return sum(1 for _ in path.open("r", encoding="utf-8", errors="ignore"))
    except Exception:
        return 0


# â”€â”€â”€ íŒŒì¼ ìŠ¤ìº” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def scan_files(root: Path, verbose: bool = False) -> list[dict]:
    """ë£¨íŠ¸ì—ì„œ ëª¨ë“  íŒŒì¼ì„ ì¬ê·€ ìŠ¤ìº”í•˜ì—¬ ë©”íƒ€ë°ì´í„° ë°˜í™˜."""
    results = []
    for path in sorted(root.rglob("*")):
        # ë¬´ì‹œí•  ë””ë ‰í† ë¦¬/íŒŒì¼ ê±´ë„ˆëœ€
        if any(part in IGNORE_DIRS for part in path.parts):
            continue
        if path.name in IGNORE_FILES:
            continue
        if not path.is_file():
            continue

        rel = path.relative_to(root)
        ext = path.suffix.lower()
        stat = path.stat()

        entry = {
            "path": str(rel),
            "abs": path,
            "ext": ext,
            "category": EXT_CATEGORIES.get(ext, "Other"),
            "size_bytes": stat.st_size,
            "lines": count_lines(path) if ext in (".html", ".css", ".js", ".md", ".py", ".sh", ".json") else 0,
        }
        results.append(entry)
        log(f"Scanned: {rel} ({entry['category']}, {entry['lines']} lines)", verbose=verbose)

    return results


# â”€â”€â”€ HTML ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_html(files: list[dict], root: Path) -> dict:
    """HTML íŒŒì¼ì—ì„œ ë§í¬, ìŠ¤í¬ë¦½íŠ¸, ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ ì¶”ì¶œí•˜ê³  ëˆ„ë½ í™•ì¸."""
    issues = []
    references = {"scripts": [], "styles": [], "images": [], "links": [], "partials": []}

    html_files = [f for f in files if f["ext"] == ".html"]

    for f in html_files:
        content = f["abs"].read_text(encoding="utf-8", errors="ignore")
        fpath = f["path"]

        # src ì°¸ì¡° (script, img)
        for match in re.finditer(r'(?:src|href)\s*=\s*["\']([^"\']+)["\']', content):
            ref = match.group(1)
            if ref.startswith(("http", "//", "#", "mailto:")):
                continue  # ì™¸ë¶€ ë§í¬ ë¬´ì‹œ

            ext = Path(ref).suffix.lower()
            category = EXT_CATEGORIES.get(ext, "")

            if category == "JavaScript":
                references["scripts"].append((fpath, ref))
            elif category == "CSS":
                references["styles"].append((fpath, ref))
            elif category == "Image":
                references["images"].append((fpath, ref))
            elif ext == ".html":
                if "partials/" in ref:
                    references["partials"].append((fpath, ref))
                else:
                    references["links"].append((fpath, ref))

        # fetch() í˜¸ì¶œë¡œ ë¡œë“œë˜ëŠ” partial
        for match in re.finditer(r'fetch\s*\(\s*["\']([^"\']+\.html)["\']', content):
            ref = match.group(1)
            references["partials"].append((fpath, f"fetch:{ref}"))

    # ëˆ„ë½ íŒŒì¼ í™•ì¸
    all_refs = (
        references["scripts"]
        + references["styles"]
        + references["images"]
        + references["links"]
        + references["partials"]
    )
    existing_paths = {f["path"] for f in files}

    for src_file, ref in all_refs:
        clean_ref = ref.replace("fetch:", "")
        # ìƒëŒ€ ê²½ë¡œ í•´ì„: src_file ê¸°ì¤€ OR root ê¸°ì¤€ ì‹œë„
        candidates = [
            clean_ref.lstrip("/"),
            str(Path(src_file).parent / clean_ref),
        ]
        found = any(c in existing_paths for c in candidates)
        if not found:
            issues.append({
                "type": "missing_file",
                "severity": "HIGH",
                "source": src_file,
                "ref": clean_ref,
                "message": f"ì°¸ì¡°ëœ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: `{clean_ref}` (in `{src_file}`)",
            })

    # TODO ì£¼ì„ ìˆ˜ì§‘
    todo_pattern = re.compile(r"<!--\s*(TODO|FIXME|HACK|XXX)[:\s](.+?)-->", re.IGNORECASE)
    for f in html_files:
        content = f["abs"].read_text(encoding="utf-8", errors="ignore")
        for m in todo_pattern.finditer(content):
            issues.append({
                "type": "todo",
                "severity": "LOW",
                "source": f["path"],
                "ref": None,
                "message": f"{m.group(1)}: {m.group(2).strip()} (in `{f['path']}`)",
            })

    return {"issues": issues, "references": references}


# â”€â”€â”€ JS ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_js(files: list[dict]) -> dict:
    """JavaScript íŒŒì¼ì—ì„œ íŒ¨í„´ ë° ì´ìŠˆ ë¶„ì„."""
    issues = []
    js_files = [f for f in files if f["ext"] == ".js"]

    patterns_found = []
    for f in js_files:
        content = f["abs"].read_text(encoding="utf-8", errors="ignore")

        # ì˜¤ë˜ëœ íŒ¨í„´ íƒì§€
        if "var " in content:
            issues.append({
                "type": "old_syntax",
                "severity": "LOW",
                "source": f["path"],
                "ref": None,
                "message": f"`var` ì‚¬ìš© ê°ì§€ (let/const ê¶Œì¥): `{f['path']}`",
            })

        # console.log íƒì§€ (í”„ë¡œë•ì…˜ì—ì„œ ì œê±° ê¶Œì¥)
        console_count = len(re.findall(r"\bconsole\.(log|warn|error)\b", content))
        if console_count > 0:
            issues.append({
                "type": "debug_code",
                "severity": "LOW",
                "source": f["path"],
                "ref": None,
                "message": f"console í˜¸ì¶œ {console_count}ê°œ ë°œê²¬ (í”„ë¡œë•ì…˜ ì œê±° ê¶Œì¥): `{f['path']}`",
            })

        # ì¢‹ì€ íŒ¨í„´ íƒì§€
        if "IntersectionObserver" in content:
            patterns_found.append(("IntersectionObserver", f["path"]))
        if "prefers-reduced-motion" in content:
            patterns_found.append(("ReducedMotion", f["path"]))
        if "DOMContentLoaded" in content:
            patterns_found.append(("DOMContentLoaded", f["path"]))

    return {"issues": issues, "patterns": patterns_found}


# â”€â”€â”€ CSS ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_css(files: list[dict]) -> dict:
    """CSS íŒŒì¼ì—ì„œ íŒ¨í„´ ë° ì´ìŠˆ ë¶„ì„."""
    issues = []
    css_files = [f for f in files if f["ext"] == ".css"]
    features = []

    for f in css_files:
        content = f["abs"].read_text(encoding="utf-8", errors="ignore")

        # ì¢‹ì€ CSS íŒ¨í„´
        for feature in ["clamp(", "var(--", "grid-template", "IntersectionObserver", "@keyframes", "prefers-reduced-motion"]:
            if feature in content:
                features.append((feature, f["path"]))

        # ì ì¬ì  ì´ìŠˆ: !important ë‚¨ìš©
        important_count = content.count("!important")
        if important_count > 3:
            issues.append({
                "type": "css_specificity",
                "severity": "LOW",
                "source": f["path"],
                "ref": None,
                "message": f"`!important` {important_count}íšŒ ì‚¬ìš© (ìµœì†Œí™” ê¶Œì¥): `{f['path']}`",
            })

        # êµ¬í˜• flexbox ì ‘ë‘ì‚¬
        if "-webkit-flex" in content or "-ms-flex" in content:
            issues.append({
                "type": "vendor_prefix",
                "severity": "LOW",
                "source": f["path"],
                "ref": None,
                "message": f"êµ¬í˜• vendor prefix ì‚¬ìš©: `{f['path']}`",
            })

    return {"issues": issues, "features": features}


# â”€â”€â”€ êµ¬ì¡° ë¶„ì„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_structure(files: list[dict], root: Path) -> dict:
    """ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„ ë° ê¶Œì¥ êµ¬ì¡°ì™€ ë¹„êµ."""
    issues = []
    dirs = defaultdict(list)

    for f in files:
        parts = Path(f["path"]).parts
        top = parts[0] if len(parts) > 1 else "(root)"
        dirs[top].append(f)

    # ê¶Œì¥ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
    recommended = {
        "index.html": "ë©”ì¸ ì§„ì…ì ",
        "styles/styles.css": "ë©”ì¸ CSS",
        "main.js": "ë©”ì¸ JavaScript",
        "partials/header.html": "í—¤ë” ì»´í¬ë„ŒíŠ¸",
        "partials/footer.html": "í‘¸í„° ì»´í¬ë„ŒíŠ¸",
        "README.md": "í”„ë¡œì íŠ¸ ë¬¸ì„œ",
    }
    existing = {f["path"] for f in files}
    for rec_path, desc in recommended.items():
        if rec_path not in existing:
            issues.append({
                "type": "missing_recommended",
                "severity": "MEDIUM",
                "source": None,
                "ref": rec_path,
                "message": f"ê¶Œì¥ íŒŒì¼ ì—†ìŒ: `{rec_path}` ({desc})",
            })

    # js/, css/ ë””ë ‰í† ë¦¬ ì—†ì´ ë£¨íŠ¸ì— JS íŒŒì¼ ì¡´ì¬
    root_js = [f for f in files if f["ext"] == ".js" and "/" not in f["path"]]
    if root_js and "js" not in dirs:
        issues.append({
            "type": "structure",
            "severity": "MEDIUM",
            "source": None,
            "ref": None,
            "message": f"JS íŒŒì¼({len(root_js)}ê°œ)ì´ ë£¨íŠ¸ì— ìœ„ì¹˜ - `js/` ë””ë ‰í† ë¦¬ë¡œ ì´ë™ ê¶Œì¥",
        })

    return {"issues": issues, "dirs": dict(dirs)}


# â”€â”€â”€ ë¦¬í¬íŠ¸ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def generate_report(
    files: list[dict],
    html_result: dict,
    js_result: dict,
    css_result: dict,
    struct_result: dict,
    root: Path,
) -> str:
    """ë¶„ì„ ê²°ê³¼ë¥¼ Markdown ë¦¬í¬íŠ¸ë¡œ ë³€í™˜."""

    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    total_issues = (
        html_result["issues"] + js_result["issues"] + css_result["issues"] + struct_result["issues"]
    )
    high = [i for i in total_issues if i["severity"] == "HIGH"]
    medium = [i for i in total_issues if i["severity"] == "MEDIUM"]
    low = [i for i in total_issues if i["severity"] == "LOW"]

    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    cat_stats = defaultdict(lambda: {"count": 0, "lines": 0, "size": 0})
    for f in files:
        cat = f["category"]
        cat_stats[cat]["count"] += 1
        cat_stats[cat]["lines"] += f["lines"]
        cat_stats[cat]["size"] += f["size_bytes"]

    lines = [
        f"# Re-Archive ë ˆí¬ì§€í† ë¦¬ ë¶„ì„ ë¦¬í¬íŠ¸",
        f"",
        f"> ìƒì„±ì¼ì‹œ: {now}  ",
        f"> ë¶„ì„ ì—ì´ì „íŠ¸: `agents/01_analyze.py`",
        f"",
        f"---",
        f"",
        f"## ìš”ì•½",
        f"",
        f"| í•­ëª© | ê°’ |",
        f"|------|-----|",
        f"| ì´ íŒŒì¼ ìˆ˜ | {len(files)}ê°œ |",
        f"| ì´ ì½”ë“œ ë¼ì¸ | {sum(f['lines'] for f in files):,}ì¤„ |",
        f"| ì´ í¬ê¸° | {sum(f['size_bytes'] for f in files) / 1024:.1f} KB |",
        f"| ë°œê²¬ëœ ì´ìŠˆ | ğŸ”´ HIGH {len(high)} / ğŸŸ¡ MEDIUM {len(medium)} / ğŸŸ¢ LOW {len(low)} |",
        f"",
        f"---",
        f"",
        f"## íŒŒì¼ êµ¬ì¡°",
        f"",
        f"```",
        f"{root.name}/",
    ]

    # íŠ¸ë¦¬ í˜•íƒœ ì¶œë ¥
    dirs = defaultdict(list)
    root_files = []
    for f in sorted(files, key=lambda x: x["path"]):
        parts = Path(f["path"]).parts
        if len(parts) == 1:
            root_files.append(f)
        else:
            dirs[parts[0]].append(f)

    for f in root_files:
        lines.append(f"â”œâ”€â”€ {f['path']}")

    dir_list = sorted(dirs.keys())
    for i, d in enumerate(dir_list):
        prefix = "â””â”€â”€" if i == len(dir_list) - 1 else "â”œâ”€â”€"
        lines.append(f"{prefix} {d}/")
        dir_files = sorted(dirs[d], key=lambda x: x["path"])
        for j, f in enumerate(dir_files):
            fname = Path(f["path"]).name
            sub_prefix = "    â””â”€â”€" if j == len(dir_files) - 1 else "    â”œâ”€â”€"
            lines.append(f"{sub_prefix} {fname}")

    lines += [
        f"```",
        f"",
        f"---",
        f"",
        f"## ì¹´í…Œê³ ë¦¬ë³„ í†µê³„",
        f"",
        f"| ì¹´í…Œê³ ë¦¬ | íŒŒì¼ ìˆ˜ | ì´ ë¼ì¸ | ì´ í¬ê¸° |",
        f"|---------|--------|--------|--------|",
    ]
    for cat, stats in sorted(cat_stats.items()):
        size_str = f"{stats['size'] / 1024:.1f} KB" if stats["size"] > 1024 else f"{stats['size']} B"
        lines.append(f"| {cat} | {stats['count']} | {stats['lines']:,} | {size_str} |")

    lines += [
        f"",
        f"---",
        f"",
        f"## HTML ì°¸ì¡° ë¶„ì„",
        f"",
    ]

    refs = html_result["references"]
    for ref_type, ref_list in refs.items():
        if ref_list:
            lines.append(f"### {ref_type.capitalize()} ({len(ref_list)}ê°œ)")
            for src, ref in ref_list[:10]:  # ìµœëŒ€ 10ê°œ í‘œì‹œ
                lines.append(f"- `{ref}` â† `{src}`")
            if len(ref_list) > 10:
                lines.append(f"- _(ì™¸ {len(ref_list) - 10}ê°œ)_")
            lines.append("")

    lines += [
        f"---",
        f"",
        f"## JavaScript íŒ¨í„´ ë¶„ì„",
        f"",
        f"### ë°œê²¬ëœ í˜„ëŒ€ì  íŒ¨í„´",
        f"",
    ]
    for pattern, fpath in js_result["patterns"]:
        lines.append(f"- âœ… `{pattern}` in `{fpath}`")

    lines += [
        f"",
        f"---",
        f"",
        f"## CSS ê¸°ëŠ¥ ë¶„ì„",
        f"",
        f"### ë°œê²¬ëœ í˜„ëŒ€ì  CSS ê¸°ëŠ¥",
        f"",
    ]
    for feature, fpath in css_result["features"]:
        lines.append(f"- âœ… `{feature}` in `{fpath}`")

    lines += [
        f"",
        f"---",
        f"",
        f"## ë°œê²¬ëœ ì´ìŠˆ",
        f"",
    ]

    if not total_issues:
        lines.append("ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. âœ…")
    else:
        for severity, color, issues_list in [
            ("HIGH", "ğŸ”´", high),
            ("MEDIUM", "ğŸŸ¡", medium),
            ("LOW", "ğŸŸ¢", low),
        ]:
            if issues_list:
                lines.append(f"### {color} {severity} ({len(issues_list)}ê°œ)")
                lines.append("")
                for issue in issues_list:
                    lines.append(f"- **[{issue['type']}]** {issue['message']}")
                lines.append("")

    lines += [
        f"---",
        f"",
        f"## ê¶Œì¥ ê°œì„  ì‚¬í•­",
        f"",
        f"ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ í†µí•´ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ê°œì„  ì‚¬í•­:",
        f"",
        f"1. **`02_find_skills.py`** - ëˆ„ë½ëœ ê¸°ëŠ¥(whatif.js, contact form ë“±) ìë™ ìƒì„±",
        f"2. **`03_improve_structure.py`** - í´ë” êµ¬ì¡° ì¬í¸ì„± (`js/`, `css/`, `assets/` ë¶„ë¦¬)",
        f"3. **`04_check.py`** - HTML ìœ íš¨ì„±, ê¹¨ì§„ ë§í¬, ì ‘ê·¼ì„± ê²€ì‚¬",
        f"4. **`05_publish.py`** - README ì—…ë°ì´íŠ¸ ë° GitHub Pages ë°°í¬",
        f"",
        f"---",
        f"",
        f"_ì´ ë¦¬í¬íŠ¸ëŠ” `agents/01_analyze.py`ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤._",
    ]

    return "\n".join(lines)


# â”€â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(description="Re-Archive ë ˆí¬ì§€í† ë¦¬ ë¶„ì„ ì—ì´ì „íŠ¸")
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    parser.add_argument("--output", "-o", default=str(OUTPUT_FILE), help="ë¦¬í¬íŠ¸ ì¶œë ¥ ê²½ë¡œ")
    parser.add_argument("--json", action="store_true", help="JSON í˜•ì‹ìœ¼ë¡œë„ ì¶œë ¥")
    args = parser.parse_args()

    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    print("\nğŸ” Re-Archive Repository Analysis Agent")
    print("=" * 50)

    # 1. íŒŒì¼ ìŠ¤ìº”
    print("\n[1/5] íŒŒì¼ ìŠ¤ìº” ì¤‘...")
    files = scan_files(ROOT, verbose=args.verbose)
    print(f"      â†’ {len(files)}ê°œ íŒŒì¼ ë°œê²¬")

    # 2. HTML ë¶„ì„
    print("\n[2/5] HTML ë¶„ì„ ì¤‘...")
    html_result = analyze_html(files, ROOT)
    print(f"      â†’ HTML ì´ìŠˆ {len(html_result['issues'])}ê°œ ë°œê²¬")

    # 3. JS ë¶„ì„
    print("\n[3/5] JavaScript ë¶„ì„ ì¤‘...")
    js_result = analyze_js(files)
    print(f"      â†’ JS ì´ìŠˆ {len(js_result['issues'])}ê°œ ë°œê²¬")

    # 4. CSS ë¶„ì„
    print("\n[4/5] CSS ë¶„ì„ ì¤‘...")
    css_result = analyze_css(files)
    print(f"      â†’ CSS ì´ìŠˆ {len(css_result['issues'])}ê°œ ë°œê²¬")

    # 5. êµ¬ì¡° ë¶„ì„
    print("\n[5/5] ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„ ì¤‘...")
    struct_result = analyze_structure(files, ROOT)
    print(f"      â†’ êµ¬ì¡° ì´ìŠˆ {len(struct_result['issues'])}ê°œ ë°œê²¬")

    # ë¦¬í¬íŠ¸ ìƒì„±
    print(f"\nğŸ“„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ â†’ {output_path}")
    report = generate_report(files, html_result, js_result, css_result, struct_result, ROOT)
    output_path.write_text(report, encoding="utf-8")
    print(f"   âœ“ ì €ì¥ ì™„ë£Œ: {output_path}")

    # JSON ì¶œë ¥ (ì„ íƒ)
    if args.json:
        json_path = output_path.with_suffix(".json")
        data = {
            "files": [{k: v for k, v in f.items() if k != "abs"} for f in files],
            "html": {**html_result, "references": {k: list(v) for k, v in html_result["references"].items()}},
            "js": js_result,
            "css": css_result,
            "structure": struct_result,
        }
        json_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"   âœ“ JSON ì €ì¥: {json_path}")

    # ìš”ì•½ ì¶œë ¥
    all_issues = html_result["issues"] + js_result["issues"] + css_result["issues"] + struct_result["issues"]
    high = sum(1 for i in all_issues if i["severity"] == "HIGH")
    medium = sum(1 for i in all_issues if i["severity"] == "MEDIUM")
    low = sum(1 for i in all_issues if i["severity"] == "LOW")

    print(f"\n{'=' * 50}")
    print(f"âœ… ë¶„ì„ ì™„ë£Œ")
    print(f"   íŒŒì¼: {len(files)}ê°œ | ì´ìŠˆ: ğŸ”´{high} / ğŸŸ¡{medium} / ğŸŸ¢{low}")
    print(f"   ë¦¬í¬íŠ¸: {output_path}")
    print()


if __name__ == "__main__":
    main()
